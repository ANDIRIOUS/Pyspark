{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo:\n",
    " Analizar la eficiencia de los jugadores en términos generales y por posición, así como determinar la contribución al equipo por jugador tomando en cuenta los datos obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usarás la base de datos del archivo 'fusbol.csv' para obtener tus datos. Checa la estructura del archivo para ver si es necesario limpiar la informacion, ver su estructura y así sea más fácil completar la tarea. Besos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1:\n",
    "Carga la base de datos en un DataFrame de Pyspark (con 2 nucleos). Valida los rangos de los valores donde sea aplicable, así como su corrección (en caso de ser necesaria). \n",
    "Después, utilizando las variables más relevantes como 'Ast/90', 'PassCmp%', etc., concluye qué ligas tienen los mejores jugadores por posición. Es decir, si los mejores jugadores defensas son de la liga francesa, inglesa, etc., por ejemplo.\n",
    "Como cada persona tiene una definición de \"mejor\", utiliza las siguientes metricas por posición:\n",
    "- Delanteros: npG+A/90 y npxG+xA/90\n",
    "- Medios: KeyPass/90 y PassCmp%\n",
    "- Defensas: PressSucc% y Interceptions/90\n",
    "\n",
    "Con los resultados obtenidos, grafica por posición para que tu conclusión tenga un respaldo visual también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, when, avg, percent_rank\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar los datos desde un archivo CSV\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfusbol.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inferSchema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Mostrar las primeras filas y el esquema del DataFrame para entender la estructura de los datos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Cargar los datos desde un archivo CSV\n",
    "df = spark.read.csv('fusbol.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Mostrar las primeras filas y el esquema del DataFrame para entender la estructura de los datos\n",
    "df.show(5)\n",
    "df.printSchema()\n",
    "\n",
    "# Limpiar y validar los datos si es necesario (asumiendo validaciones hipotéticas)\n",
    "df = df.withColumn(\"Ast/90\", when(col(\"Ast/90\") < 0, 0).otherwise(col(\"Ast/90\")))\n",
    "df = df.withColumn(\"PassCmp%\", when(col(\"PassCmp%\") > 100, 100).otherwise(col(\"PassCmp%\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar delanteros y calcular métricas relevantes\n",
    "delanteros = df.filter(col(\"Pos\") == \"Forward\")\n",
    "delanteros = delanteros.withColumn(\"npG+A/90\", col(\"npG/90\") + col(\"Ast/90\"))\n",
    "delanteros = delanteros.withColumn(\"npxG+xA/90\", col(\"npxG/90\") + col(\"xA/90\"))\n",
    "\n",
    "# Agregar la liga como una dimensión de análisis\n",
    "mejores_delanteros = delanteros.groupBy(\"Squad\").agg(\n",
    "    _sum(\"npG+A/90\").alias(\"Total npG+A/90\"),\n",
    "    _sum(\"npxG+xA/90\").alias(\"Total npxG+xA/90\")\n",
    ").orderBy(\"Total npG+A/90\", ascending=False)\n",
    "\n",
    "mejores_delanteros.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar medios y calcular métricas relevantes\n",
    "medios = df.filter(col(\"Pos\").contains(\"MF\"))\n",
    "medios = medios.withColumn(\"KeyPass/90\", col(\"KeyPass/90\"))\n",
    "medios = medios.withColumn(\"PassCmp%\", col(\"PassCmp%\"))\n",
    "\n",
    "# Agregar la liga como una dimensión de análisis\n",
    "mejores_medios = medios.groupBy(\"Comp\").agg(\n",
    "    _sum(\"KeyPass/90\").alias(\"Total KeyPass/90\"),\n",
    "    _sum(\"PassCmp%\").alias(\"Total PassCmp%\")\n",
    ").orderBy(\"Total KeyPass/90\", ascending=False)\n",
    "\n",
    "mejores_medios.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar defensas y calcular métricas relevantes\n",
    "defensas = df.filter(col(\"Pos\").contains(\"DF\"))\n",
    "defensas = defensas.withColumn(\"Interceptions/90\", col(\"Interceptions/90\"))\n",
    "\n",
    "# Agregar la liga como una dimensión de análisis\n",
    "mejores_defensas = defensas.groupBy(\"Comp\").agg(\n",
    "    _sum(\"Interceptions/90\").alias(\"Total Interceptions/90\")\n",
    ").orderBy(\"Total Interceptions/90\", ascending=False)\n",
    "\n",
    "mejores_defensas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Iniciar una sesión de Spark\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Analisis de Futbol\").getOrCreate()\n",
    "\n",
    "# Cargar los datos desde un archivo CSV\n",
    "df = spark.read.csv('fusbol.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Contar cuántos jugadores hay por posición\n",
    "positions_count = df.groupBy(\"Pos\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir a pandas DataFrame para graficar\n",
    "positions_count_pd = positions_count.toPandas()\n",
    "\n",
    "# Crear un gráfico de barras\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(positions_count_pd['Pos'], positions_count_pd['count'], color='skyblue')\n",
    "plt.xlabel('Posición')\n",
    "plt.ylabel('Número de Jugadores')\n",
    "plt.title('Cantidad de Jugadores por Posición')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Ejercicio 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hagamos algo un poco más interesante. Escoge algún jugador de todos los disponibles y toma 5 metricas, las que quieras. Debes concluir en qué percentil se encuentra el jugador en esas métricas que escogiste. Obviamente, vas a comparar sus valores con todos los demás con los que comparte posición y liga, para no tener un sesgo y que la información no pierda robustez. Por último, genera un DataFrame de Pyspark con todos los datos solicitados. Muestra el DataFrame y conviertelo a otro de tipo pandas. Muestra los dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, percent_rank, monotonically_increasing_id\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Iniciar sesión de Spark\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Analisis de Jugadores\").getOrCreate()\n",
    "\n",
    "# Cargar el DataFrame\n",
    "df = spark.read.csv('fusbol.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Elegir un jugador aleatorio para el ejemplo, supongamos que el primero\n",
    "jugador = df.first()\n",
    "# Métricas seleccionadas: 'Shots/90', 'Interceptions/90', 'PassCmp%', 'Ast/90', 'Touches/90'\n",
    "metricas = ['Shots/90', 'Interceptions/90', 'PassCmp%', 'Ast/90', 'Touches/90']\n",
    "jugador_pos = jugador['Pos']\n",
    "jugador_liga = jugador['Comp']\n",
    "\n",
    "# Filtrar jugadores de la misma posición y liga\n",
    "df_filtrado = df.filter((col('Pos') == jugador_pos) & (col('Comp') == jugador_liga))\n",
    "\n",
    "# Calcular los percentiles para cada métrica\n",
    "window = Window.partitionBy(\"Pos\", \"Comp\").orderBy([col(m) for m in metricas])\n",
    "percentiles = df_filtrado.withColumn(\"index\", monotonically_increasing_id()).select(\n",
    "    \"Player\",\n",
    "    *[col(m) for m in metricas],\n",
    "    *[percent_rank().over(window).alias(m + '_percentile') for m in metricas]\n",
    ").filter(col(\"index\") == 0)  # Suponemos que es el primer jugador\n",
    "\n",
    "# Mostrar los resultados\n",
    "percentiles.show()\n",
    "percentiles_pd = percentiles.toPandas()\n",
    "percentiles_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
